{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNv0YEyjE5oPiV7gYXytvLT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-tomas/data-mining/blob/main/notebooks/data_mining_4.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhDsu8knBExh"
      },
      "source": [
        "# Extracción de características"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnvcISE_c97V"
      },
      "source": [
        "## Pasos previos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsKmX-5V49-2"
      },
      "source": [
        "# Importamos las librerías de Python que necesitaremos en este notebook\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # Evitamos warnings indeseados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv2GyAVFjCNm"
      },
      "source": [
        "Vamos a trabajar de nuevo con dos conjuntos de datos en formato CSV\n",
        "\n",
        "* `pokemon.csv`: contiene 41 características de cada uno de los 802 Pokemon desde la generación 1 hasta la 7\n",
        "* `ansur_ii.csv`: *Anthropometric Survey of US Army Personnel* contiene 93 medidas corporales realizadas a 6.068 adultos (4.082 hombres y 1.986 mujeres)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1k3VoZdV9QQ"
      },
      "source": [
        "# Obtención de los ficheros CSV con los datos\n",
        "\n",
        "!wget https://raw.githubusercontent.com/d-tomas/data-mining/main/datasets/pokemon.csv\n",
        "!wget https://raw.githubusercontent.com/d-tomas/data-mining/main/datasets/ansur_ii.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANO78ZDJcFUP"
      },
      "source": [
        "# Cargamos los datos de Pokemon en formato CSV\n",
        "\n",
        "data_pokemon = pd.read_csv('pokemon.csv')\n",
        "data_pokemon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8xJpHrLdgXm"
      },
      "source": [
        "# Cargamos los datos de ANSUR II en formato CSV\n",
        "\n",
        "data_ansur = pd.read_csv('ansur_ii.csv')\n",
        "data_ansur"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY1WR1JyIQ6G"
      },
      "source": [
        "## Extracción manual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lW6y7fqIQf_"
      },
      "source": [
        "# Cuando se conce bien un dataset, se pueden combinar variables antiguas en otras nuevas\n",
        "# En el dataset ANSUR II se puede utilizar el índice de masa corporal para combinar peso y estatura\n",
        "# Body Mass Index (BMI) = peso (kg) / estatura^2 (m^2)\n",
        "\n",
        "data_body = pd.DataFrame(data_ansur['weightkg'] / 10)  # El peso está en hectogramos (??). Lo pasamos a kilogramos\n",
        "data_body['stature'] = data_ansur['stature'] / 1000  # La estatura está en milímetros. La pasamos a metros\n",
        "data_body['BMI'] = data_body['weightkg'] / data_body['stature'] ** 2\n",
        "data_body"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxGBlEAXSIbB"
      },
      "source": [
        "# Si añadimos esta información al dataset, los valores de altura y peso pueden quedar obsoletos y los podemos eliminar\n",
        "\n",
        "data_body.drop(['weightkg', 'stature'], axis=1, inplace=True)\n",
        "data_body"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIi-xAVAELAy"
      },
      "source": [
        " ## Análisis de componentes principales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "covfgMo0DJnV"
      },
      "source": [
        "# Vamos a analizar primero qué relación hay entre el tamaño de las manos y el tamaño de los pies\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.scatterplot(data=data_ansur, x='handlength', y='footlength')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQddYeugEM1P"
      },
      "source": [
        "# Para poder aplicar PCA hay que escalar las características primero\n",
        "# El método 'StandardScaler' centra y escala (media 0 y varianza 1) cada característica de manera independiente\n",
        "\n",
        "scaler = StandardScaler()\n",
        "data_scaler = pd.DataFrame(scaler.fit_transform(data_ansur[['handlength', 'footlength']]), columns=data_ansur[['handlength', 'footlength']].columns)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.scatterplot(data=data_scaler, x='handlength', y='footlength')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZY55sRHLU2F"
      },
      "source": [
        "# Podemos ver cómo ha quedado la media y la desviación tras el escalado\n",
        "\n",
        "print('handlength')\n",
        "print('Media: %f' % data_scaler['handlength'].mean())\n",
        "print('Desviación: %f' % data_scaler['handlength'].std())\n",
        "print('footlength')\n",
        "print('Media: %f' % data_scaler['footlength'].mean())\n",
        "print('Desviación: %f' % data_scaler['footlength'].std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixh3dIfRU6rr"
      },
      "source": [
        "# Entre las dos variables hay una fuerte correlación (el escalado no afecta)\n",
        "\n",
        "data_scaler.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mooWWTVnHZ1o"
      },
      "source": [
        "# Usamos 'PCA' y 'fit_transform' sobre los datos escalados para calcular los componentes principales\n",
        "\n",
        "pca = PCA()\n",
        "data_pca = pca.fit_transform(data_scaler)\n",
        "pd.DataFrame(data_pca).corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXE3G59UJDEq"
      },
      "source": [
        "# Al mostrar el conjunto resultante, se ve que los datos ya no guardan correlación\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.scatterplot(x=data_pca[:, 0], y=data_pca[:, 1])\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZsVj2NjKvBb"
      },
      "source": [
        "# Podemos usar el atributo 'explained_variance_ratio_' como métrica para evaluar la utilidad de los componentes principales\n",
        "# Indica el porcentaje de varianza que se atribuye a cada uno de los componentes seleccionados\n",
        "# El primer componente explica el 92% de la varianza en los datos y el segundo el resto\n",
        "\n",
        "pca.explained_variance_ratio_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcGo6tvGcYOE"
      },
      "source": [
        "# Un inconveniente de PCA es que los componentes con los que te quedas son difíciles de interpretar\n",
        "# Para entender mejor los componentes se puede mirar el atributo 'components_'\n",
        "# Indica hasta qué punto cada componente se ve afectado por una característica específica\n",
        "# La característica que tenga el mayor efecto positivo o negativo sobre el componente puede usarse para darle significado\n",
        "# En el primer componente [0.71, 0.71] el efecto de ambas características es el mismo\n",
        "# El primer componente se ve tanto afectado por el tamaño de los pies como por el de las manos\n",
        "# El segundo componente [0.71, -0.71] se ve negativamente afectado por el tamaño de los pies\n",
        "# La gente que tiene una puntuación alta para el segundo componente tiene los pies pequeños comparados con sus manos\n",
        "\n",
        "pca.components_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szqyRKH2LMxj"
      },
      "source": [
        "# Vamos a ver otro ejemplo con un conjunto mayor de características altamente correlacionadas\n",
        "# Cogemos todo el conjunto de datos de ANSUR II\n",
        "\n",
        "scaler = StandardScaler()\n",
        "data_num = data_ansur.select_dtypes(exclude='object')  # Nos quedamos con las columnas numéricas\n",
        "data_scaler = pd.DataFrame(scaler.fit_transform(data_num), columns=data_num.columns)\n",
        "pca = PCA()\n",
        "pca.fit(data_scaler)\n",
        "pca.explained_variance_ratio_  # Los dos primeros componentes explican 54,17% y 12,09% de la varianza"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOgl7fU0NtXE"
      },
      "source": [
        "# Podemos usar 'cumsum' para ver cuánta varianza podemos explicar en total usando un cierto número de componentes\n",
        "# En este ejemplo, los dos primeros componentes nos permiten explicar el 66,27% de la varianza en los datos\n",
        "# Con los diez primeros componentes podemos mantener el 82,87% de la varianza\n",
        "\n",
        "pca.explained_variance_ratio_.cumsum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8S8a2fLX9aU"
      },
      "source": [
        "# Como PCA implica un escalado previo, se pueden combinar ambas operaciones con un pipeline\n",
        "\n",
        "pipe = Pipeline([('scaler', StandardScaler()), ('reducer', PCA())])\n",
        "pc = pipe.fit_transform(data_num)\n",
        "pc[:, :2]  # Dos primeros componentes principales"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCen3mQpZWr_"
      },
      "source": [
        "# El dataset de ANSUR II tiene una serie de columnas categoriales\n",
        "# Podemos ver si estas características están alineadas con las fuentes más importantes de varianza en los datos\n",
        "\n",
        "categories = data_ansur.select_dtypes(include='object')\n",
        "categories.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DVLKPlpZyOO"
      },
      "source": [
        "# Vamos a ver cómo está relacionado el género con la varianza\n",
        "# Tomamos los dos primeros componentes principales\n",
        "\n",
        "categories['PC1'] = pc[:, 0]\n",
        "categories['PC2'] = pc[:, 1]\n",
        "sns.scatterplot(data=categories, x='PC1', y='PC2', hue='Gender', alpha=0.4)\n",
        "plt.show()  # Se aprecia más efecto en la primera componente principal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxz1wkHwd1et"
      },
      "source": [
        "# Podemos decirle a PCA cuántos componentes queremos que calcule con el atributo 'n_components'\n",
        "# También podemos decirle la proporción mínima de varianza que queremos mantener\n",
        "\n",
        "data_num = data_pokemon.select_dtypes(exclude='object')\n",
        "data_num.dropna(inplace=True)  # Debemos eliminar NaN\n",
        "pipe = Pipeline([('scaler', StandardScaler()), ('reducer', PCA(n_components=0.9))])  # Mantenemos el 90% de la varianza\n",
        "pipe.fit(data_num)\n",
        "len(pipe.steps[1][1].components_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbthdUKlfnnm"
      },
      "source": [
        "# Podemos visualizar donde se concentra la mayoría de varianza explicada de los componentes principales\n",
        "# El punto donde se da el cambio brusco en la gráfica se conoce como codo (elbow)\n",
        "# Es un buen punto de partida para decidir el número de componentes a mantener\n",
        "\n",
        "var = pipe.steps[1][1].explained_variance_ratio_\n",
        "sns.lineplot(data=var)\n",
        "plt.xlabel('Principal component index')\n",
        "plt.ylabel('Explained variance ratio')\n",
        "plt.show()  # Podríamos mantener 5 componentes en este caso"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf3KSjzscgIT"
      },
      "source": [
        "# Referencias\n",
        "\n",
        "* [The Complete Pokemon Dataset](https://www.kaggle.com/rounakbanik/pokemon)\n",
        "* [ANSUR II](https://www.openlab.psu.edu/ansur2/)\n",
        "* [Características de ANSUR II explicadas](http://tools.openlab.psu.edu/publicData/ANSURII-MFR.pdf)"
      ]
    }
  ]
}